{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python notebook for Make Your Own Neural Network\n",
    "# code for a 3-layer neural network, and code for learning the MNIST dataset\n",
    "# (c) Laugh, 2019\n",
    "# license is GPLv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# scipy.speaial for the sigmoid function expit()\n",
    "import scipy.special\n",
    "# library for plotting arrays\n",
    "import matplotlib.pyplot as plt\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wih = np.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        self.inverse_activation_function = lambda x: scipy.special.logit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = np.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * np.dot((output_errors * final_outputs * (1.0 - final_outputs)), np.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * np.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), np.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    \n",
    "    # backquery the neural network\n",
    "    # we'll use the same termnimology to each item, \n",
    "    # eg target are the values at the right of the network, albeit used as input\n",
    "    # eg hidden_output is the signal to the right of the middle nodes\n",
    "    def backquery(self, targets_list):\n",
    "        # transpose the targets list to a vertical array\n",
    "        final_outputs = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate the signal into the final output layer\n",
    "        final_inputs = self.inverse_activation_function(final_outputs)\n",
    "\n",
    "        # calculate the signal out of the hidden layer\n",
    "        hidden_outputs = np.dot(self.who.T, final_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        hidden_outputs -= np.min(hidden_outputs)\n",
    "        hidden_outputs /= np.max(hidden_outputs)\n",
    "        hidden_outputs *= 0.98\n",
    "        hidden_outputs += 0.01\n",
    "        \n",
    "        # calculate the signal into the hidden layer\n",
    "        hidden_inputs = self.inverse_activation_function(hidden_outputs)\n",
    "        \n",
    "        # calculate the signal out of the input layer\n",
    "        inputs = np.dot(self.wih.T, hidden_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        inputs -= np.min(inputs)\n",
    "        inputs /= np.max(inputs)\n",
    "        inputs *= 0.98\n",
    "        inputs += 0.01\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate is 0.1\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"mnist_dataset/mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs\n",
    "        inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = np.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist test data CSV file into a list\n",
    "test_data_file = open(\"mnist_dataset/mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split the records by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    # scale and shift the inputs\n",
    "    inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = np.argmax(outputs)\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9732\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = np.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper to load data from PNG image files\n",
    "import imageio\n",
    "# glob helps select multiple files using patterns\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ...  my_own_images\\my_own_01.png\n",
      "0.01\n",
      "1.0\n",
      "loading ...  my_own_images\\my_own_02.png\n",
      "0.01\n",
      "0.9767059\n",
      "loading ...  my_own_images\\my_own_03.png\n",
      "0.01\n",
      "1.0\n",
      "loading ...  my_own_images\\my_own_04.png\n",
      "0.01\n",
      "1.0\n",
      "loading ...  my_own_images\\my_own_05.png\n",
      "0.01\n",
      "1.0\n",
      "loading ...  my_own_images\\my_own_06.png\n",
      "0.01\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# our own image test data set\n",
    "our_own_dataset = []\n",
    "\n",
    "# load the png image data as test data set\n",
    "for image_file_name in glob.glob('my_own_images/my_own_0?.png'):\n",
    "    \n",
    "    # use the filename to set the correct label\n",
    "    label = int(image_file_name[-5:-4])\n",
    "    \n",
    "    # load image data from png files into an array\n",
    "    print (\"loading ... \", image_file_name)\n",
    "    img_array = imageio.imread(image_file_name, as_gray=True)\n",
    "    \n",
    "    # reshape from 28x28 to list of 784 values, invert values\n",
    "    img_data  = 255.0 - img_array.reshape(784)\n",
    "    \n",
    "    # then scale data to range from 0.01 to 1.0\n",
    "    img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "    print(np.min(img_data))\n",
    "    print(np.max(img_data))\n",
    "    \n",
    "    # append label and image data  to test data set\n",
    "    record = np.append(label,img_data)\n",
    "    our_own_dataset.append(record)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.07080731e-04]\n",
      " [1.75098809e-03]\n",
      " [6.68254085e-04]\n",
      " [9.74793094e-01]\n",
      " [1.42344888e-03]\n",
      " [7.98368672e-03]\n",
      " [4.94005329e-04]\n",
      " [5.87786532e-03]\n",
      " [8.93859726e-04]\n",
      " [3.51134501e-03]]\n",
      "network says  3\n",
      "no match!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the neural network with our own images\n",
    "\n",
    "# record to test\n",
    "item = 0\n",
    "\n",
    "# plot image\n",
    "plt.imshow(our_own_dataset[item][1:].reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "# correct answer is first value\n",
    "correct_label = our_own_dataset[item][0]\n",
    "# data is remaining values\n",
    "inputs = our_own_dataset[item][1:]\n",
    "\n",
    "# query the network\n",
    "outputs = n.query(inputs)\n",
    "print (outputs)\n",
    "\n",
    "# the index of the highest value corresponds to the label\n",
    "label = np.argmax(outputs)\n",
    "print(\"network says \", label)\n",
    "# append correct or incorrect to list\n",
    "if (label == correct_label):\n",
    "    print (\"match!\")\n",
    "else:\n",
    "    print (\"no match!\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2e1287a2e48>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the network backwards, given a label, see what image it produces\n",
    "\n",
    "# label to test\n",
    "label = 0\n",
    "# create the output signals for this label\n",
    "targets = np.zeros(output_nodes) + 0.01\n",
    "# all_values[0] is the target label for this record\n",
    "targets[label] = 0.99\n",
    "print(targets)\n",
    "\n",
    "# get image data\n",
    "image_data = n.backquery(targets)\n",
    "\n",
    "# plot image data\n",
    "plt.imshow(image_data.reshape(28,28), cmap='Greys', interpolation='None')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
